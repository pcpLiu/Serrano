//
//  dot_product_op.swift
//  serrano
//
//  Created by ZHONGHAO LIU on 6/16/17.
//  Copyright Â© 2017 ZHONGHAO LIU. All rights reserved.
//

import Foundation
import Accelerate
import Metal
#if  !((arch(i386)  || arch(x86_64)) && os(iOS)) // prevent build error on simulaor
    import MetalPerformanceShaders
#endif

/// This struct corresponds to the `MatrixDimInfo` struct in file 'matrix_mult_op.metal'
public struct MatrixDimInfo {
    var M: MetalUInt // number of rows in A
    var N: MetalUInt // number of cols in B
    var K: MetalUInt // number of cols in A, number of rows in B
    var stride: MetalUShort // element stride in bytes
    var beta: MetalFloat // scale of output
}


/// Two kernels
///
/// - Single: Caclulate a single element each thread
/// - SubMatrix: Caculate a submatrix each thread
public enum MatrixMultKernel {
    case Single
    case SubMatrix
}


/**
matrix multiplication.

## Transpose input tensors
Opertor's attributes `transposeA` and `transposeB` indicating if tranposing input tensors before doing calculation.
And if any or both of them are set  to `true`, all caulcation and input/output validation will be doing __after__ transposing.

## Metal performance shader support
By default, operator tries to use [MPSMatrixMultiplication](https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication) in `MetalPerformanceShaders`.
But on some devices which [do not support `MetalPerformanceShaders`](https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf), we use self kernel.

## Multiple input
This operator could takein multiple input. Currently, it support multiple input `A` and single input `B`.
If `inputTensors` contains more than 2 elements, operator will view last element as input `B` and all previous element as input `A`s.

*/
public class MatrixMultOperator: ComputableOperator {
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // MARK: - Attributes
    
    /// The submatrix size in Metal calcualtion.
    /// Should be the same as `SUBMATRIX_SIZE` in `matrix_mult_op.metal`
    public static let METAL_SUBMATRIX_SIZE = 4
    
    /// Operator label. Conforms to `ComputableOperator`
    public var operatorLabel: String
    
    /// This operator does not operator on GPU. Conforms to `ComputableOperator`
    public var metalKernelFuncLabel:String = "MatrixMult"
    
    /// Conforms to `ComputableOperator`
    public var computationDelegate: OperatorCalculationDelegate?
    
    /// Conforms to `ComputableOperator`
    public var inputTensors: [Tensor]?
    
    /// Conforms to `ComputableOperator`
    public var outputTensors: [Tensor]?
    
    /// Whether transpose inputA before calculation
    public var transposeA: Bool
    
    /// Whether transpose inputB before calcualtion
    public var transposeB: Bool
    
    /// If `true`, operator will not call `inputOutputTensorsCheck()` before doing calculation.
    /// This is used inside framework to speed up in situation we know it will not be wrong.
    public var disableInputOutputCheck: Bool = false
    
    /// Indicate if this operator would do paramter update.
    public var trainable: Bool = false
    
    /// Kernel to choose
    public var kernel: MatrixMultKernel
    
    /// The mapping type of this operator.
    /// `Constant` for this operator.
    public var mapType: OperatorMappingType {
        get {
            return OperatorMappingType.Constant
        }
    }
    
    /// Default in training mode
    public var forwadMode: GraphForwardMode = GraphForwardMode.training
    
    /// Matrix multiplication cannot do in-place calculation
    public var inPlaceble: Bool = false
    
    /// If use MPS. Default is `false`
    internal var disabledMPS: Bool = false
    
    /// beta for mstrix calculation, if want to add into output tensor, set this to 1
    internal var matrixBeta: Float = 0.0
    
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // MARK: - Initializer
    
    public init(operatorLabel: String = "MatrixMultOperator",
                computationDelegate: OperatorCalculationDelegate? = nil,
                transposeA: Bool = false, transposeB: Bool = false,
                inputTensors: [Tensor]? = nil, outputTensors: [Tensor]? = nil,
                kernel: MatrixMultKernel = MatrixMultKernel.Single,
                disableInputOutputCheck: Bool = false) {
        self.operatorLabel = operatorLabel
        self.computationDelegate = computationDelegate
        self.inputTensors = inputTensors
        self.outputTensors = outputTensors
        self.transposeA = transposeA
        self.transposeB = transposeB
        self.kernel = kernel
        self.disableInputOutputCheck = disableInputOutputCheck
    }
    
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // MARK: - Conforms to `ComputableOperator`
    
    /// Check the input shapes. Following same rule of matrix multiplication.
    ///
    /// - Note: This function will transpose shape first and then calcualte output shape.
    ///
    /// - Parameter shapes: input shapes
    /// - Returns: return shapes
    public func outputShape(shapeArray shapes: [TensorShape]) -> [TensorShape]? {
        // >=2 shapes
        guard shapes.count >= 2 else {
            SerranoLogging.errorLogging(message: "Operator \(self.operatorLabel) expect more than 2 shapes, given \(shapes.count)",
                file: "\(#file)", function: "\(#function)", line: "\(#line)")
            return nil
        }
        
        var shapeAs = shapes[0..<shapes.count-1]
        var shapeB = shapes.last!
        var outputShapes = [TensorShape]()

        // do transpose
        if self.transposeA {
            for (i,shapeA) in shapeAs.enumerated() {
                shapeAs[i] = shapeA.transposed()
            }
        }
        if self.transposeB {
            shapeB = shapeB.transposed()
        }
        
        for shapeA in shapeAs {
            // shapeA validation
            guard shapeA.rank == 2 && shapeB.rank == 2 else {
                SerranoLogging.errorLogging(message: "Shape A and shape B should have ranks as 2. Given shapeA rank \(shapeA.rank) , shapeB rank \(shapeB.rank) ",
                    file: "\(#file)", function: "\(#function)", line: "\(#line)")
                return nil
            }
            
            // multiplication rule validation
            guard shapeA.shapeArray[1] == shapeB.shapeArray[0] else {
                SerranoLogging.errorLogging(message: "Shape A and shape B does not follow matrix multiply rule. Given shapeA \(shapeA.shapeArray) , shapeB \(shapeB.shapeArray) ",
                    file: "\(#file)", function: "\(#function)", line: "\(#line)")
                return nil
            }
            
            outputShapes.append(TensorShape(dataType: shapeA.dataType, shape: [shapeA.shapeArray[0], shapeB.shapeArray[1]]))
        }
        
        
        return outputShapes
    }
    
    
    /// Check if assigned `inputTensors` and `outputTensors` valid
    ///
    /// - Note: This function will first transposes input tensors' shapes according to attributes `transposeA` and `transposeB`,
    ///            and then validate the shapes.
    ///
    /// - Returns: the result and erro message if possible
    public func inputOutputTensorsCheck() -> (check: Bool, msg: String) {
        // not nil inputs
        guard self.inputTensors != nil else {
            return (false, "Input tensors are nil")
        }
        
        // >=2 input tensors
        guard self.inputTensors!.count >= 2 else {
            return (false, "Invalid input tneosr. Requires more than 2, given \(self.inputTensors!.count)")
        }
        
        // output not nil
        guard self.outputTensors != nil else {
            return (false, "Output tensors are nil")
        }
        
        // output tensors count match
        guard self.outputTensors!.count == self.inputTensors!.count - 1 else {
            return (false, "Invalid number of output tensors. Requires \(self.inputTensors!.count - 1), given \(self.inputTensors!.count)")
        }
        
        // check dimension
        let inputShapes = self.inputTensors!.map { $0.shape }
        let checkResult = self.outputShape(shapeArray: inputShapes)
        guard checkResult != nil else {
            return (false, "Invalid input tneosrs. See logs for details.")
        }
        
        // outptu dimension
        let outputShapes = self.outputTensors!.map {$0.shape}
        for (outShape, checkShape) in zip(outputShapes, checkResult!) {
            guard outShape.shapeArray == checkShape.shapeArray else {
                return (false, "Invalid output tensor. Expecting shape \(checkShape.shapeArray), given \(outShape.shapeArray)")
            }
        }
        
        return (true, "")
    }
    
    
    /// Compute sync
    ///
    /// - Parameter computationMode: mode
    public func compute(_ computationMode: OperatorComputationMode = SerranoEngine.configuredEngine.defaultComputationMode) {
        // check
        if self.disableInputOutputCheck {
            let (pass, msg) = self.inputOutputTensorsCheck()
            guard pass else {
                SerranoLogging.errorLogging(message: "Operator \(self.operatorLabel) calculation aborted cause invalid input tensors or output tensors: \(msg)", file: "\(#file)", function: "\(#function)", line: "\(#line)")
                fatalError()
            }
        }
        
        self.computationDelegate?.operatorWillBeginComputation(self)
        
        switch computationMode {
        case .GPU:
            if !SerranoEngine.configuredEngine.hasAvailableGPU() {
                SerranoLogging.warningLogging(message: "Serrano Engine has no available configured GPU device. Use CPU doing calculation instead.",
                                              file: "\(#file)", function: "\(#function)", line: "\(#line)")
                self.cpu()
            } else {
                self.gpu()
            }
        case .CPU:
            self.cpu()
        case .Auto:
            if self.outputTensors![0].count > 4000000 && SerranoEngine.configuredEngine.hasAvailableGPU() {
                self.gpu()
            } else {
                self.cpu()
            }
        }
        self.computationDelegate?.operatorDidEndComputation(self, outputTensors: self.outputTensors!)
    }
    
    
    /// Compute async
    ///
    /// - Parameter computationMode: mode
    public func computeAsync(_ computationMode: OperatorComputationMode = SerranoEngine.configuredEngine.defaultComputationMode) {
        // delegation check
        OperatorUtils.delegateNilWarning(op: self, file: "\(#file)", function: "\(#function)", line: #line)
        
        DispatchQueue.global(qos: .userInitiated).async {
            self.compute(computationMode)
        }
    }
    
    /// Calulate grads sync.
    /// All unary operator return grads tensor with same number and shape as attribute `inputTensors`.
    ///
    /// - Parameters:
    ///   - computationMode: computationMode
    ///   - upGrds: upGrds
    /// - Returns: return grads tensor
    public func gradCompute(_ computationMode: OperatorComputationMode) -> [String: DataSymbolSupportedDataType] {
        //TODO: Implementation
        fatalError("Not implemented")
    }
    
    /// Cal grads async
    ///
    /// - Parameters:
    ///   - computationMode: computationMode
    ///   - upGrds: upGrds
    public func gradComputAsync(_ computationMode: OperatorComputationMode) {
        // check delegate
        OperatorUtils.delegateNilWarning(op: self, file: "\(#file)", function: "\(#function)", line: #line)
        
        DispatchQueue.global(qos: .userInitiated).async {
            _ = self.gradCompute(computationMode)
        }
    }
    
    /// Update params if possible.
    /// No update parameters for binary operators.
    ///
    /// - Parameters:
    ///   - grads: grads tensor list
    ///   - LR: learning rate
    public func updateParams(grads: [Tensor], LR: Float) {
        return
    }
    
    /// Do nothing
    public func bindParamSymbols(_ symbols: [GraphSymbol]) {
        // DO NOTHING
    }
    
    /// This operator has no parameters.
    ///
    /// - Returns: An empty array
    public func paramSymbols() -> [GraphSymbol] {
        return [GraphSymbol]()
    }
    
    /// Get M, N, K attributes
    ///
    /// - Returns: M, N, K
    internal func MNKFetch(tensorA: Tensor, tensorB: Tensor) -> (M: Int, N: Int, K: Int) {
        var M = tensorA.shape.shapeArray[0]
        if self.transposeA {
            M = tensorA.shape.shapeArray[1]
        }
        var N = tensorB.shape.shapeArray[1]
        if self.transposeB {
            N = tensorB.shape.shapeArray[0]
        }
        var K = tensorA.shape.shapeArray[1]
        if self.transposeA {
            K = tensorA.shape.shapeArray[0]
        }
        return (M, N, K)
    }
    
    /// Use `BLAS` `cblas_sgemm` to do calculation
    internal func cpu() {
        let workGroup = DispatchGroup()
        let inputB = self.inputTensors!.last!
        let inputBAddress = inputB.contentsAddress
        
        for (input, output) in zip(self.inputTensors!, self.outputTensors!) {
            let inputAAddress = input.contentsAddress
            let outCAddress = output.contentsAddress
            
            let (M, N, K) = self.MNKFetch(tensorA: input, tensorB: inputB)
            
            let lda = Int32(input.shape.shapeArray[1])
            let ldb = Int32(inputB.shape.shapeArray[1])
            let ldc = Int32(output.shape.shapeArray[1])
            
            cblas_sgemm(CblasRowMajor, cblasTrans(self.transposeA), cblasTrans(self.transposeB), Int32(M), Int32(N), Int32(K),
                        1.0, inputAAddress, lda, inputBAddress, ldb, self.matrixBeta, outCAddress, ldc)
        }
        workGroup.wait()
    }
    
    
    /// This method choose proper kernel or MPS to do calculation
    internal func gpu() {
        // Use MPS if possible
        if !self.disabledMPS && MetalHardwareChecker.supportMPS() {
            if #available(OSX 10.13, iOS 10.0, *) {
                self.gpu_kernel_MPS()
                return
            }
        }
        
        // choose kernel
        if self.transposeA && !self.transposeB {
            self.gpu_kernel_submatrix()
        } else {
            self.gpu_kernel_single()
        }
    }

    /// Do calculation of inputA and transpoedB.
    /// `transposedInputB` is supposed already transposed
    ///
    /// - Parameters:
    ///   - inputABuffer: inputA
    ///   - inputBBufferTransposed: transposedInputB
    ///   - outputCBuffer: outputCBuffer
    ///   - dimInfo: dimInfo
    ///   - kernel: kernel
    internal func gpu_single(inputABuffer: MTLBufferResource, inputBBufferTransposed: MTLBufferResource, outputCBuffer: MTLBufferResource,
                             dimInfo: inout MatrixDimInfo, kernel: MTLComputePipelineState) {
        let commandBuffer = SerranoEngine.configuredEngine.serranoCommandQueue?.makeCommandBuffer()
        guard commandBuffer != nil else {
            fatalError("[Serrano] Failed to make new command buffer.")
        }
        
        // Encoders.
        let encoder = commandBuffer!.makeComputeCommandEncoder()
        encoder.setComputePipelineState(kernel)
        encoder.setBuffer(inputABuffer.buffer, offset: inputABuffer.offset, at: 0)
        encoder.setBuffer(inputBBufferTransposed.buffer, offset: inputBBufferTransposed.offset, at: 1)
        encoder.setBuffer(outputCBuffer.buffer, offset: outputCBuffer.offset, at: 2)
        encoder.setBytes(&dimInfo, length: MemoryLayout<MatrixDimInfo>.stride, at: 3)
        
        /// Calculate grid
        let threadsPerThreadgroup = MTLSizeMake(kernel.threadExecutionWidth,
                                                kernel.maxTotalThreadsPerThreadgroup / kernel.threadExecutionWidth,
                                                1)
        let threadgroupsPerGrid = MTLSizeMake((Int(dimInfo.M) + threadsPerThreadgroup.width - 1) / threadsPerThreadgroup.width,
                                              (Int(dimInfo.N) + threadsPerThreadgroup.height - 1) / threadsPerThreadgroup.height,
                                              1)
        encoder.dispatchThreadgroups(threadgroupsPerGrid, threadsPerThreadgroup: threadsPerThreadgroup)
        encoder.endEncoding()

        if !SerranoLogging.release {
            SerranoLogging.stdLogging(message: "Dispatch group configured with threadgroupsPerGrid: \(threadgroupsPerGrid), threadsPerThreadgroup: \(threadsPerThreadgroup) requested by operator \(self.operatorLabel)",
                file: "\(#file)", function: "\(#function)", line: "\(#line)",  loggingLevel: .LowLevel)
        }
        
        
        // commit command buffer
        commandBuffer!.commit()
        commandBuffer!.waitUntilCompleted()
    }
    
    internal func gpu_kernel_single() {
        let (kernel, info) = SerranoEngine.configuredEngine.loadGPUKernel(kernelLabel: "MatrixMult_Single")
        guard kernel != nil else {
            fatalError("[Serrano] Failed to load kernel MatrixMult_Single. Info: \(info)")
        }
        
        // transpose B process
        var inputBTransposed = self.inputTensors!.last!
        if !self.transposeB {
            let transposeB = SerranoResourceManager.globalManager.allocateUnamangedTensor(inputBTransposed.shape.transposed())
            let transOp = TransposeOperator(inputTensors: [inputBTransposed], outputTensors: [transposeB])
            transOp.disableInputOutputCheck = true
            transOp.compute(.GPU)
            inputBTransposed = transposeB
        }
        let inputBBufferTransposed = inputBTransposed.gpuBufferResource()
        
        // do calcualtion
        let workGroup = DispatchGroup()
        if self.transposeA {
            for (inputA, output) in zip(self.inputTensors![0..<self.inputTensors!.count-1], self.outputTensors!) {
                workGroup.enter()
                DispatchQueue.global(qos: .userInitiated).async {
                    let transA = SerranoResourceManager.globalManager.allocateUnamangedTensor(inputA.shape.transposed())
                    let transOp = TransposeOperator(inputTensors: [inputA], outputTensors: [transA])
                    transOp.disableInputOutputCheck = true
                    transOp.compute(.GPU)
                    
                    let (M,N,K) = self.MNKFetch(tensorA: inputA, tensorB: self.inputTensors!.last!) // here use raw inputA, inputB to get M,N,K
                    var info = MatrixDimInfo(M: MetalUInt(M), N: MetalUInt(N), K: MetalUInt(K), stride: MetalUShort(MemoryLayout<Float>.stride), beta: self.matrixBeta.metalFloat)
                    self.gpu_single(inputABuffer: transA.gpuBufferResource(), inputBBufferTransposed: inputBBufferTransposed,
                                    outputCBuffer: output.gpuBufferResource(), dimInfo: &info, kernel: kernel!)
                    workGroup.leave()
                }
            }
        } else {
            for (inputA, output) in zip(self.inputTensors![0..<self.inputTensors!.count-1], self.outputTensors!) {
                workGroup.enter()
                DispatchQueue.global(qos: .userInitiated).async {
                    let (M,N,K) = self.MNKFetch(tensorA: inputA, tensorB: self.inputTensors!.last!) // here use raw inputB to get M,N,K
                    var info = MatrixDimInfo(M: MetalUInt(M), N: MetalUInt(N), K: MetalUInt(K), stride: MetalUShort(MemoryLayout<Float>.stride), beta: self.matrixBeta.metalFloat)
                    self.gpu_single(inputABuffer: inputA.gpuBufferResource(), inputBBufferTransposed: inputBBufferTransposed,
                                    outputCBuffer: output.gpuBufferResource(), dimInfo: &info, kernel: kernel!)
                    workGroup.leave()
                }
            }
        }
        
        workGroup.wait()
    }
    
    
    /// Do matrix multiplication with submatrix kernel.
    ///
    /// - Parameters:
    ///   - inputATransposeBuffer: transposed A buffer
    ///   - inputBBuffer: inputBBuffer
    ///   - outputCBuffer: outputCBuffer
    ///   - dimInfo: dimInfo
    ///   - kernel: kernel
    internal func gpu_submatrix(inputATransposeBuffer: MTLBufferResource, inputBBuffer: MTLBufferResource,
                                outputCBuffer: MTLBufferResource,
                                dimInfo: inout MatrixDimInfo, kernel: MTLComputePipelineState) {
        let commandBuffer = SerranoEngine.configuredEngine.serranoCommandQueue?.makeCommandBuffer()
        guard commandBuffer != nil else {
            fatalError("[Serrano] Failed to make new command buffer.")
        }
        
        // Encoders.
        let encoder = commandBuffer!.makeComputeCommandEncoder()
        encoder.setComputePipelineState(kernel)
        encoder.setBuffer(inputATransposeBuffer.buffer, offset: inputATransposeBuffer.offset, at: 0)
        encoder.setBuffer(inputBBuffer.buffer, offset: inputBBuffer.offset, at: 1)
        encoder.setBuffer(outputCBuffer.buffer, offset: outputCBuffer.offset, at: 2)
        encoder.setBytes(&dimInfo, length: MemoryLayout<MatrixDimInfo>.stride, at: 3)
        
        /// Calculate grid
        let threadsPerThreadgroup = MTLSizeMake(MatrixMultOperator.METAL_SUBMATRIX_SIZE,
                                                MatrixMultOperator.METAL_SUBMATRIX_SIZE,
                                                1)
        let threadgroupsPerGrid = MTLSizeMake((Int(dimInfo.M) + threadsPerThreadgroup.width - 1) / threadsPerThreadgroup.width,
                                              (Int(dimInfo.N) + threadsPerThreadgroup.height - 1) / threadsPerThreadgroup.height,
                                              1)
        encoder.dispatchThreadgroups(threadgroupsPerGrid, threadsPerThreadgroup: threadsPerThreadgroup)
        encoder.endEncoding()
        
        if !SerranoLogging.release {
            SerranoLogging.stdLogging(message: "Dispatch group configured with threadgroupsPerGrid: \(threadgroupsPerGrid), threadsPerThreadgroup: \(threadsPerThreadgroup) requested by operator \(self.operatorLabel)",
                file: "\(#file)", function: "\(#function)", line: "\(#line)",  loggingLevel: .LowLevel)
        }
        
        // commit command buffer
        commandBuffer!.commit()
        commandBuffer!.waitUntilCompleted()
    }
    
    /// - Note:  There's no any transposing processing in this function cause
    ///          in function `gpu()` it only dispatches suitable inputs to this function.
    internal func gpu_kernel_submatrix() {
        let (kernel, info) = SerranoEngine.configuredEngine.loadGPUKernel(kernelLabel: "MatrixMult_submatrix")
        guard kernel != nil else {
            fatalError("[Serrano] Failed to load kernel MatrixMult_Single. Info: \(info)")
        }
        
        let inputBBuffer = self.inputTensors!.last!.gpuBufferResource()
        
        // do calcualtion
        let workGroup = DispatchGroup()

        for (inputA, output) in zip(self.inputTensors![0..<self.inputTensors!.count-1], self.outputTensors!) {
            workGroup.enter()
            DispatchQueue.global(qos: .userInitiated).async {
                let (M,N,K) = self.MNKFetch(tensorA: inputA, tensorB: self.inputTensors!.last!) // here use raw inputA and inputB to get M,N,K
                var info = MatrixDimInfo(M: MetalUInt(M), N: MetalUInt(N), K: MetalUInt(K), stride: MetalUShort(MemoryLayout<Float>.stride), beta: self.matrixBeta.metalFloat)
                self.gpu_submatrix(inputATransposeBuffer: inputA.gpuBufferResource(), inputBBuffer: inputBBuffer,
                                   outputCBuffer: output.gpuBufferResource(),
                                   dimInfo: &info, kernel: kernel!)
                workGroup.leave()
            }
        }
        workGroup.wait()
    }
    
    @available(OSX 10.13, iOS 10.0, *)
    internal func gpu_kernel_MPS() {
        #if  !((arch(i386)  || arch(x86_64)) && os(iOS))
        // input B
        let inputB = self.inputTensors!.last!
        let inputBBuffer = SerranoResourceManager.globalManager.allocateUnmanagedMTLBuffe(inputB)
        let inputBMatrixDescript =  MPSMatrixDescriptor(dimensions: inputB.shape.shapeArray[0], columns: inputB.shape.shapeArray[1],
                                                rowBytes:  inputB.shape.shapeArray[1] * MemoryLayout<Float>.stride,
                                                dataType: .float32)
        let inputBMatrix = MPSMatrix(buffer: inputBBuffer, descriptor: inputBMatrixDescript)
        
        for (inputA, output) in zip(self.inputTensors![0..<self.inputTensors!.count-1], self.outputTensors!) {
            // INPUT A
            let inputABuffer = SerranoResourceManager.globalManager.allocateUnmanagedMTLBuffe(inputA)
            let inputAMatrixDescript = MPSMatrixDescriptor(dimensions: inputA.shape.shapeArray[0], columns: inputA.shape.shapeArray[1],
                                                            rowBytes:  inputA.shape.shapeArray[1] * MemoryLayout<Float>.stride,
                                                            dataType: .float32)
            let inputAMatrix = MPSMatrix(buffer: inputABuffer, descriptor: inputAMatrixDescript)
            
            // output
            let outputBuffer = SerranoResourceManager.globalManager.allocateUnmanagedMTLBuffe(output)
            let outputMatrixDescript = MPSMatrixDescriptor(dimensions: output.shape.shapeArray[0], columns: output.shape.shapeArray[1],
                                                           rowBytes:  output.shape.shapeArray[1] * MemoryLayout<Float>.stride,
                                                           dataType: .float32)
            let outputAMatrix = MPSMatrix(buffer: outputBuffer, descriptor: outputMatrixDescript)
            
            // do calculation
            let (M, N, K) = MNKFetch(tensorA: inputA, tensorB: inputB)
            let kernel = MPSMatrixMultiplication(device: SerranoEngine.configuredEngine.GPUDevice!,
                                                 transposeLeft: self.transposeA, transposeRight: self.transposeB,
                                                 resultRows: M, resultColumns: N,
                                                 interiorColumns: K, alpha: 1, beta: Double(self.matrixBeta))
            
            let commandBuffer = SerranoEngine.configuredEngine.serranoCommandQueue!.makeCommandBuffer()
            kernel.encode(commandBuffer: commandBuffer, leftMatrix: inputAMatrix, rightMatrix: inputBMatrix, resultMatrix: outputAMatrix)
            commandBuffer.commit()
            commandBuffer.waitUntilCompleted()
        }
        #endif
    }
    
}
