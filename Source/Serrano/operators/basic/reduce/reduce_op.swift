//
//  reduce_op.swift
//  serrano
//
//  Created by ZHONGHAO LIU on 6/27/17.
//  Copyright Â© 2017 ZHONGHAO LIU. All rights reserved.
//

import Foundation
import Metal
import Accelerate
import Dispatch


/**
The abstract class for all reduce operators. Should not be used directly.
A reduce operator do some aggregate calculation along given axes.
An example given by TensorFlow is [here](https://www.tensorflow.org/api_docs/python/tf/reduce_sum).
*/
public class ReduceOperator: ComputableOperator {
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // MARK: - Attributes
    
    public var computationDelegate: OperatorCalculationDelegate?
    
    public var metalKernelFuncLabel: String
    
    public var operatorLabel: String
    
    public var inputTensors: [Tensor]?
    
    public var outputTensors: [Tensor]?
    
    /// The axes to do the computation
    public var axis: [Int] {
        didSet {
            self.axis = Array(Set(self.axis)) // remove duplicates
        }
    }
    
    /// Indicate if keep dimensions in result tensor.
    /// This just affects result tensor's `shape` attributes.
    /// Default `false`
    public var keepDim: Bool = false
    
    /// The element compuation block in CPU mode.
    /// In most cases, subclass should just override this part in `init` method instead overriding the whole `cpu()` method.
    /// The firat pointer is the input tensor,
    //// the second is the output tensor
    public lazy var cpuComputeBlock:  (Tensor, Tensor, [Int]) -> Void = { (inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
        print("NEED OVERLOAD")
    }
    
    /// If `true`, operator will not check the `upGrads`'s shape.
    /// This is used inside framework to speed up in situation we know it will not be wrong.
    /// Cases like auto generated differentiation graph.
    public var disableUpGradShapeCheck: Bool = false
    
    /// If `true`, operator will not call `inputOutputTensorsCheck()` before doing calculation.
    /// This is used inside framework to speed up in situation we know it will not be wrong.
    public var disableInputOutputCheck: Bool = false
    
    /// Indicate if this operator would do paramter update.
    ///
    /// - Note: All `UnaryOperators` are not trainable.
    public var trainable: Bool = false

    /// The mapping type of this operator.
    /// `OneToOne` for this operator.
    public var mapType: OperatorMappingType {
        get {
            return OperatorMappingType.OneToOne
        }
    }
    
    /// Reduce operator cannot do in-place calculation
    public var inPlaceble: Bool = false
    
    /// Default in training mode
    public var forwadMode: GraphForwardMode = GraphForwardMode.training
    
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // MARK: - Initializers
    
    init(computationDelegate: OperatorCalculationDelegate?,
                operatorLabel: String = "NEED OVERRIDE",
                metalKernelFuncLabel kernelLabel: String = "NEED OVERRIDE",
                inputTensors: [Tensor]?, outputTensors: [Tensor]?,
                axis: [Int]) {
        self.computationDelegate = computationDelegate
        self.operatorLabel = operatorLabel
        self.inputTensors = inputTensors
        self.outputTensors = outputTensors
        self.metalKernelFuncLabel = kernelLabel
        self.axis = Array(Set(axis))
        self.cpuComputeBlock = { (inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
            print("NEED OVERLOAD")
        }
    }
    
    
    /// Conenience init.
    ///
    /// - Parameters:
    ///   - inputTensors: inputTensors description
    ///   - outputTensors: outputTensors description
    ///   - axis: axis description
    public convenience required init(inputTensors: [Tensor]? = nil, outputTensors: [Tensor]? = nil, axis: [Int]) {
        self.init(computationDelegate: nil, inputTensors: inputTensors, outputTensors: outputTensors, axis: axis)
    }
    
    
    /// Conenience init.
    ///
    /// - Parameters:
    ///   - axis: axis
    ///   - keepDim: keepDim
    public convenience init(axis: [Int], keepDim: Bool) {
        self.init(computationDelegate: nil, inputTensors: nil, outputTensors: nil, axis: axis)
        self.keepDim = keepDim
    }
    
    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // MARK: - Methods
    
    
    /// Check if for each input shape operator could do reduce operation with `axis` attribute value.
    ///
    /// - Parameter shapes: shapes description
    /// - Returns: return value description
    public func outputShape(shapeArray shapes: [TensorShape]) -> [TensorShape]? {
        var outShapes = [TensorShape]()
        
        // empty input warning
        if shapes.count == 0 {
            SerranoLogging.warningLogging(message: "The input shapes contains no element.",
                                          file: "\(#file)", function: "\(#function)", line: "\(#line)")
            return outShapes
        }
        
        for shape in shapes {
            // check rank
            guard shape.rank >= self.axis.count else {
                SerranoLogging.errorLogging(message: "Input shape [\(shape)] is not valid on target axis: \(self.axis)",
                                            file: "\(#file)", function: "\(#function)", line: "\(#line)")
                return nil
            }
            
            
            var outputShapeArray = shape.shapeArray
            // ax dim value check
            for ax in self.axis {
                guard ax < outputShapeArray.count && ax >= 0 else {
                    SerranoLogging.errorLogging(message: "Input shape [\(shape)] is not valid on target axis: \(self.axis)",
                        file: "\(#file)", function: "\(#function)", line: "\(#line)")
                    return nil
                }
                outputShapeArray[ax] = 1
            }
            
            // not keeping dim, del dim
            if !self.keepDim {
                outputShapeArray = outputShapeArray
                    .enumerated()
                    .filter{ !self.axis.contains($0.offset) }
                    .map { $0.element }
            }
            outShapes.append(TensorShape(dataType: shape.dataType, shape: outputShapeArray))
        }
        
        return outShapes
    }
    
    
    /// Validate shapes`inputTensors` and `outputTensors`.
    ///
    /// - Returns: check passing and message if not passing
    public func inputOutputTensorsCheck() -> (check: Bool, msg: String) {
        // input not nil
        guard self.inputTensors != nil else {
            return (false, "Input tensors are nil.")
        }
        
        // output not nil
        guard self.outputTensors != nil else {
            return (false, "Output tensors are nil.")
        }
        
        // count
        guard self.inputTensors!.count == self.outputTensors!.count else {
            return (false, "Input and output tensors should have same amount of tensors. " +
                           "Input: \(self.inputTensors!.count), output: \(self.outputTensors!.count).")
        }
        
        // check input shapes
        let inputShapes = self.inputTensors!.map { $0.shape }
        let outputShapesValid = self.outputShape(shapeArray: inputShapes)
        guard outputShapesValid != nil else {
            return (false, "Input tensors' shapes are not valid. Check log for detail.")
        }
        
        // check output shapes
        let outputShapes = self.outputTensors!.map { $0.shape }
        for i in 0..<outputShapesValid!.count {
            guard outputShapesValid![i] == outputShapes[i] else {
                return (false, "Shape of Output tensor \(self.outputTensors![i]) is not valid. " +
                               "Expect \(outputShapesValid![i]). Given \(outputShapes[i])")
            }
        }
        
        return (true, "")
    }
    
    
    /// Comput sync
    ///
    /// - Parameter computationMode: computationMode description
    public func compute(_ computationMode: OperatorComputationMode = SerranoEngine.configuredEngine.defaultComputationMode) {
        // check
        let (pass, msg) = self.inputOutputTensorsCheck()
        guard pass else {
            SerranoLogging.errorLogging(message: "Operator \(self.operatorLabel) calculation aborted cause invalid input tensors or output tensors: \(msg)", file: "\(#file)", function: "\(#function)", line: "\(#line)")
            fatalError()
        }
        
        self.computationDelegate?.operatorWillBeginComputation(self)
        
        self.cpu()
        
//        switch computationMode {
//        case .GPU:
//            if !SerranoEngine.configuredEngine.hasAvailableGPU() {
//                SerranoLogging.warningLogging(message: "Serrano Engine has no available configured GPU device. Use CPU doing calculation instead.", file: "\(#file)", function: "\(#function)", line: "\(#line)")
//                self.cpu()
//            } else {
//                self.gpu()
//            }
//        case .CPU:
//            self.cpu()
//        }
        self.computationDelegate?.operatorDidEndComputation(self, outputTensors: self.outputTensors!)
    }
    
    
    /// Comput async
    ///
    /// - Parameter computationMode: computationMode description
    public func computeAsync(_ computationMode: OperatorComputationMode = SerranoEngine.configuredEngine.defaultComputationMode) {
        // check delegate
        OperatorUtils.delegateNilWarning(op: self, file: "\(#file)", function: "\(#function)", line: #line)
        
        DispatchQueue.global(qos: .userInitiated).async {
            self.compute(computationMode)
        }
    }
    
    /// Calulate grads sync.
    /// All unary operator return grads tensor with same number and shape as attribute `inputTensors`.
    ///
    /// - Parameters:
    ///   - computationMode: computationMode
    /// - Returns: return grads tensor
    public func gradCompute(_ computationMode: OperatorComputationMode) -> [String: DataSymbolSupportedDataType] {
        //TODO: Implementation
        fatalError("Not implemented")
    }
    
    /// Cal grads async
    ///
    /// - Parameters:
    ///   - computationMode: computationMode
    public func gradComputAsync(_ computationMode: OperatorComputationMode) {
        // check delegate
        OperatorUtils.delegateNilWarning(op: self, file: "\(#file)", function: "\(#function)", line: #line)
        
        DispatchQueue.global(qos: .userInitiated).async {
            _ = self.gradCompute(computationMode)
        }
    }
    
    /// Update params if possible.
    /// No update parameters for binary operators.
    ///
    /// - Parameters:
    ///   - grads: grads tensor list
    ///   - LR: learning rate
    public func updateParams(grads: [Tensor], LR: Float) {
        return
    }
    
    /// This operator has no parameters. Do nothing
    ///
    public func bindParamSymbols(_ symbols: [GraphSymbol]) {
        
    }
    
    /// This operator has no parameters.
    ///
    /// - Returns: An empty array
    public func paramSymbols() -> [GraphSymbol] {
        return [GraphSymbol]()
    }
    
    internal func cpu() {
     let workGroup = DispatchGroup()
        for tensorIndex in 0..<self.inputTensors!.count {
            workGroup.enter()
            DispatchQueue.global(qos: .userInitiated).async {
                self.cpuComputeBlock(self.inputTensors![tensorIndex], self.outputTensors![tensorIndex], self.axis)
                workGroup.leave()
            }
        }
        
        workGroup.wait()
    }
    
    internal func gpu() {
        //TODO: IMPLEMENTATION
        fatalError()
    }
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

/**
Computes the sum of array elements over given axes.
*/
public class ReduceSumOperator: ReduceOperator {
    
    override init(computationDelegate: OperatorCalculationDelegate?,
         operatorLabel: String = "ReduceSumOperator",
         metalKernelFuncLabel kernelLabel: String = "ReduceSum",
         inputTensors: [Tensor]?, outputTensors: [Tensor]?,
         axis: [Int]) {
        super.init(computationDelegate: computationDelegate, operatorLabel: operatorLabel, metalKernelFuncLabel: kernelLabel,
                   inputTensors: inputTensors, outputTensors: outputTensors, axis: axis)
        // custom block
        self.cpuComputeBlock = {(inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
            let op = ReduceOperator(axis: [Int]())
            op.keepDim = true
            
            var inputAddress = inputTensor.contentsAddress
            var outptuAddress: UnsafeMutablePointer<Float>
            var inputShape = inputTensor.shape
            var intermediateTensor: Tensor = inputTensor
            var nextTensor: Tensor = outputTensor
            
            let sortedAxis = axis.sorted()
            for (axIndex, ax) in sortedAxis.enumerated() {
                // decide output address
                if axIndex != sortedAxis.count - 1 {
                    // intermediate
                    op.axis = [ax]
                    let nextShape = op.outputShape(shapeArray: [inputShape])!.first!
                    nextTensor = Tensor(repeatingValue: 0.0, tensorShape: nextShape)
                    outptuAddress = nextTensor.contentsAddress
                } else {
                    nextTensor = outputTensor
                }
                outptuAddress = nextTensor.contentsAddress
                
                // do reduce on intermediateTensor and store result to newTensor
                let preDimCount = intermediateTensor.shape.shapeArray.prefix(upTo: ax).reduce(1, *)
                let nextEntryCount = intermediateTensor.shape.shapeArray.suffix(from: ax+1).reduce(1, *)
                let entryCount = intermediateTensor.shape.shapeArray.suffix(from: ax).reduce(1, *)
                let axDim = intermediateTensor.shape.shapeArray[ax]
                for preDimIndex in 0..<preDimCount {
                    for entryIndex in 0..<nextEntryCount {
                        // calcualte sum for each element in nextTensor.
                        // vDSP_sve sums  [vDSP_Length(ax)] number of floats from [inputAddress] to [outptuAddress] with stride [entryCount]
                        vDSP_sve(inputAddress + preDimIndex*entryCount + entryIndex,
                                 nextEntryCount,
                                 outptuAddress,
                                 vDSP_Length(axDim))
                        outptuAddress += 1
                    }
                }
                
                // update input address and input shape
                intermediateTensor = nextTensor // keep it alive
                inputAddress = intermediateTensor.contentsAddress
                inputShape = intermediateTensor.shape
                
            }
        }
    }
}

/**
Computes the product of array elements over given axes.
*/
public class ReduceProductOperator: ReduceOperator {
    
    override init(computationDelegate: OperatorCalculationDelegate?,
                  operatorLabel: String = "ReduceProductOperator",
                  metalKernelFuncLabel kernelLabel: String = "ReduceProduct",
                  inputTensors: [Tensor]?, outputTensors: [Tensor]?,
                  axis: [Int]) {
        super.init(computationDelegate: computationDelegate, operatorLabel: operatorLabel, metalKernelFuncLabel: kernelLabel,
                   inputTensors: inputTensors, outputTensors: outputTensors, axis: axis)
        // custom block
        self.cpuComputeBlock = {(inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
            let op = ReduceOperator(axis: [Int]())
            op.keepDim = true
            
            var inputAddress = inputTensor.contentsAddress
            var outptuAddress: UnsafeMutablePointer<Float>
            var inputShape = inputTensor.shape
            var intermediateTensor: Tensor = inputTensor
            var nextTensor: Tensor = outputTensor
            
            let sortedAxis = axis.sorted()
            for (axIndex, ax) in sortedAxis.enumerated() {
                // decide output address
                if axIndex != sortedAxis.count - 1 {
                    // intermediate
                    op.axis = [ax]
                    let nextShape = op.outputShape(shapeArray: [inputShape])!.first!
                    nextTensor = Tensor(repeatingValue: 0.0, tensorShape: nextShape)
                    outptuAddress = nextTensor.contentsAddress
                } else {
                    nextTensor = outputTensor
                }
                outptuAddress = nextTensor.contentsAddress
                
                // do reduce on intermediateTensor and store result to newTensor
                let preDimCount = intermediateTensor.shape.shapeArray.prefix(upTo: ax).reduce(1, *)
                let nextEntryCount = intermediateTensor.shape.shapeArray.suffix(from: ax+1).reduce(1, *)
                let entryCount = intermediateTensor.shape.shapeArray.suffix(from: ax).reduce(1, *)
                let axDim = intermediateTensor.shape.shapeArray[ax]
                for preDimIndex in 0..<preDimCount {
                    for entryIndex in 0..<nextEntryCount {
                        outptuAddress[0] = 1.0
                        // calcualte sum for each element in nextTensor.
                        for j in 0..<axDim {
                            outptuAddress[0] *= (inputAddress + preDimIndex*entryCount + entryIndex + nextEntryCount * j).pointee
                        }
                        
                        outptuAddress += 1
                    }
                }
                
                // update input address and input shape
                intermediateTensor = nextTensor // keep it alive
                inputAddress = intermediateTensor.contentsAddress
                inputShape = intermediateTensor.shape
                
            }
        }
    }
}

/**
Computes the max of array elements over given axes.
*/
public class ReduceMaxOperator: ReduceOperator {
    
    override init(computationDelegate: OperatorCalculationDelegate?,
                  operatorLabel: String = "ReduceMaxOperator",
                  metalKernelFuncLabel kernelLabel: String = "ReduceMax",
                  inputTensors: [Tensor]?, outputTensors: [Tensor]?,
                  axis: [Int]) {
        super.init(computationDelegate: computationDelegate, operatorLabel: operatorLabel, metalKernelFuncLabel: kernelLabel,
                   inputTensors: inputTensors, outputTensors: outputTensors, axis: axis)
        // custom block
        self.cpuComputeBlock = {(inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
            let op = ReduceOperator(axis: [Int]())
            op.keepDim = true
            
            var inputAddress = inputTensor.contentsAddress
            var outptuAddress: UnsafeMutablePointer<Float>
            var inputShape = inputTensor.shape
            var intermediateTensor: Tensor = inputTensor
            var nextTensor: Tensor = outputTensor
            
            let sortedAxis = axis.sorted()
            for (axIndex, ax) in sortedAxis.enumerated() {
                // decide output address
                if axIndex != sortedAxis.count - 1 {
                    // intermediate
                    op.axis = [ax]
                    let nextShape = op.outputShape(shapeArray: [inputShape])!.first!
                    nextTensor = Tensor(repeatingValue: 0.0, tensorShape: nextShape)
                    outptuAddress = nextTensor.contentsAddress
                } else {
                    nextTensor = outputTensor
                }
                outptuAddress = nextTensor.contentsAddress
                
                // do reduce on intermediateTensor and store result to newTensor
                let preDimCount = intermediateTensor.shape.shapeArray.prefix(upTo: ax).reduce(1, *)
                let nextEntryCount = intermediateTensor.shape.shapeArray.suffix(from: ax+1).reduce(1, *)
                let entryCount = intermediateTensor.shape.shapeArray.suffix(from: ax).reduce(1, *)
                let axDim = intermediateTensor.shape.shapeArray[ax]
                for preDimIndex in 0..<preDimCount {
                    for entryIndex in 0..<nextEntryCount {
                        outptuAddress[0] = 1.0
                        // vDSP_maxv get max from all  [vDSP_Length(ax)] number of floats from [inputAddress] to [outptuAddress] with stride [entryCount]
                        vDSP_maxv(inputAddress + preDimIndex*entryCount + entryIndex,
                                  nextEntryCount,
                                  outptuAddress,
                                  vDSP_Length(axDim))
                        outptuAddress += 1
                    }
                }
                
                // update input address and input shape
                intermediateTensor = nextTensor // keep it alive
                inputAddress = intermediateTensor.contentsAddress
                inputShape = intermediateTensor.shape
                
            }
        }
    }
}

/**
Computes the min of array elements over given axes.
*/
public class ReduceMinOperator: ReduceOperator {
    
    override init(computationDelegate: OperatorCalculationDelegate?,
                  operatorLabel: String = "ReduceMinOperator",
                  metalKernelFuncLabel kernelLabel: String = "ReduceMin",
                  inputTensors: [Tensor]?, outputTensors: [Tensor]?,
                  axis: [Int]) {
        super.init(computationDelegate: computationDelegate, operatorLabel: operatorLabel, metalKernelFuncLabel: kernelLabel,
                   inputTensors: inputTensors, outputTensors: outputTensors, axis: axis)
        // custom block
        self.cpuComputeBlock = {(inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
            let op = ReduceOperator(axis: [Int]())
            op.keepDim = true
            
            var inputAddress = inputTensor.contentsAddress
            var outptuAddress: UnsafeMutablePointer<Float>
            var inputShape = inputTensor.shape
            var intermediateTensor: Tensor = inputTensor
            var nextTensor: Tensor = outputTensor
            
            let sortedAxis = axis.sorted()
            for (axIndex, ax) in sortedAxis.enumerated() {
                // decide output address
                if axIndex != sortedAxis.count - 1 {
                    // intermediate
                    op.axis = [ax]
                    let nextShape = op.outputShape(shapeArray: [inputShape])!.first!
                    nextTensor = Tensor(repeatingValue: 0.0, tensorShape: nextShape)
                    outptuAddress = nextTensor.contentsAddress
                } else {
                    nextTensor = outputTensor
                }
                outptuAddress = nextTensor.contentsAddress
                
                // do reduce on intermediateTensor and store result to newTensor
                let preDimCount = intermediateTensor.shape.shapeArray.prefix(upTo: ax).reduce(1, *)
                let nextEntryCount = intermediateTensor.shape.shapeArray.suffix(from: ax+1).reduce(1, *)
                let entryCount = intermediateTensor.shape.shapeArray.suffix(from: ax).reduce(1, *)
                let axDim = intermediateTensor.shape.shapeArray[ax]
                for preDimIndex in 0..<preDimCount {
                    for entryIndex in 0..<nextEntryCount {
                        outptuAddress[0] = 1.0
                        // vDSP_minv get max from all  [vDSP_Length(ax)] number of floats from [inputAddress] to [outptuAddress] with stride [entryCount]
                        vDSP_minv(inputAddress + preDimIndex*entryCount + entryIndex,
                                  nextEntryCount,
                                  outptuAddress,
                                  vDSP_Length(axDim))
                        outptuAddress += 1
                    }
                }
                
                // update input address and input shape
                intermediateTensor = nextTensor // keep it alive
                inputAddress = intermediateTensor.contentsAddress
                inputShape = intermediateTensor.shape
                
            }
        }
    }
}

/**
Computes the mean of array elements over given axes.
*/
public class ReduceMeanOperator: ReduceOperator {
    
    override init(computationDelegate: OperatorCalculationDelegate?,
                  operatorLabel: String = "ReduceMeanOperator",
                  metalKernelFuncLabel kernelLabel: String = "ReduceMean",
                  inputTensors: [Tensor]?, outputTensors: [Tensor]?,
                  axis: [Int]) {
        super.init(computationDelegate: computationDelegate, operatorLabel: operatorLabel, metalKernelFuncLabel: kernelLabel,
                   inputTensors: inputTensors, outputTensors: outputTensors, axis: axis)
        // custom block
        self.cpuComputeBlock = {(inputTensor: Tensor, outputTensor: Tensor, axis: [Int]) -> Void in
            let op = ReduceOperator(axis: [Int]())
            op.keepDim = true
            
            var inputAddress = inputTensor.contentsAddress
            var outptuAddress: UnsafeMutablePointer<Float>
            var inputShape = inputTensor.shape
            var intermediateTensor: Tensor = inputTensor
            var nextTensor: Tensor = outputTensor
            var placeHolder: Float = 1.0
            
            let sortedAxis = axis.sorted()
            for (axIndex, ax) in sortedAxis.enumerated() {
                // decide output address
                if axIndex != sortedAxis.count - 1 {
                    // intermediate
                    op.axis = [ax]
                    let nextShape = op.outputShape(shapeArray: [inputShape])!.first!
                    nextTensor = Tensor(repeatingValue: 0.0, tensorShape: nextShape)
                    outptuAddress = nextTensor.contentsAddress
                } else {
                    nextTensor = outputTensor
                }
                outptuAddress = nextTensor.contentsAddress
                
                // do reduce on intermediateTensor and store result to newTensor
                let preDimCount = intermediateTensor.shape.shapeArray.prefix(upTo: ax).reduce(1, *)
                let nextEntryCount = intermediateTensor.shape.shapeArray.suffix(from: ax+1).reduce(1, *)
                let entryCount = intermediateTensor.shape.shapeArray.suffix(from: ax).reduce(1, *)
                let axDim = intermediateTensor.shape.shapeArray[ax]
                for preDimIndex in 0..<preDimCount {
                    for entryIndex in 0..<nextEntryCount {
                        outptuAddress[0] = 1.0
                        // vDSP_normalize get mean from all  [vDSP_Length(ax)] number of floats from [inputAddress] to [outptuAddress] with stride [entryCount]
                        vDSP_normalize(inputAddress + preDimIndex*entryCount + entryIndex,
                                       nextEntryCount,
                                       nil, 0,
                                       outptuAddress,
                                       &placeHolder,
                                       vDSP_Length(axDim))
                        outptuAddress += 1
                    }
                }
                
                // update input address and input shape
                intermediateTensor = nextTensor // keep it alive
                inputAddress = intermediateTensor.contentsAddress
                inputShape = intermediateTensor.shape
                
            }
        }
    }
}
